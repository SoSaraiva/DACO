{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "dataset= pd.read_csv('dataset.csv')\n",
    "print(\"Dataset Size:\", dataset.shape)\n",
    "\n",
    "# Replace 'Unknown' with NaN in Target\n",
    "dataset['Genetic Disorder'].replace('Unknown', np.nan, inplace=True)\n",
    "dataset['Disorder Subclass'].replace('Unknown', np.nan, inplace=True)\n",
    "\n",
    "dataset.dropna(inplace=True)\n",
    "# Alocate features and labels\n",
    "\n",
    "X = dataset.iloc[:, :-2]  # Features\n",
    "y = dataset.iloc[:, -2:]  # Labels (last two columns)\n",
    "\n",
    "# Perform one-hot encoding on the categorical features\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "# drop_first is used to drop one of the columns for each categorical feature to avoid multicollinearity.\n",
    "\n",
    "# Check if the target variable has more than 2 classes\n",
    "if y.nunique().any() > 2:\n",
    "    y = pd.get_dummies(y, drop_first=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without 'unknown' class removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation, validation and test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, train_size=0.5,  random_state=1) # training as 50%\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1) # test as 25% and validations as 25%\n",
    "\n",
    "# Select and train model of classifier\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', random_state=1)\n",
    "\n",
    "clf = MultiOutputClassifier(svm_classifier)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_validation)\n",
    "\n",
    "y_validation_ds = y_validation.iloc[:, -1]\n",
    "y_validation_gd = y_validation.iloc[:, -2]\n",
    "\n",
    "y_pred_ds = y_pred[:, -1]\n",
    "y_pred_gd = y_pred[:, -2]\n",
    "\n",
    "# Apply metrics\n",
    "\n",
    "accuracy_ds = accuracy_score(y_validation_ds, y_pred_ds)\n",
    "precision_ds = precision_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "recall_ds = recall_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "f1_ds = f1_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "\n",
    "accuracy_gd = accuracy_score(y_validation_gd, y_pred_gd)\n",
    "precision_gd= precision_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "recall_gd = recall_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "f1_gd = f1_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Metrics for the Generative Disorder:\")\n",
    "print(\"Accuracy:\", accuracy_gd)\n",
    "print(\"Precision:\", precision_gd)\n",
    "print(\"Recall:\", recall_gd)\n",
    "print(\"F1 Score:\", f1_gd)\n",
    "\n",
    "print(\"\\nMetrics for the Disorder Subclass:\")\n",
    "print(\"Accuracy:\", accuracy_ds)\n",
    "print(\"Precision:\", precision_ds)\n",
    "print(\"Recall:\", recall_ds)\n",
    "print(\"F1 Score:\", f1_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 'unknown' class removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation, validation and test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, train_size=0.5,  random_state=1) # training as 50%\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1) # test as 25% and validations as 25%\n",
    "\n",
    "# Select and train model of classifier\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', random_state=1, class_weight='balanced')\n",
    "\n",
    "clf = MultiOutputClassifier(svm_classifier)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_validation)\n",
    "\n",
    "y_validation_ds = y_validation.iloc[:, -1]\n",
    "y_validation_gd = y_validation.iloc[:, -2]\n",
    "\n",
    "y_pred_ds = y_pred[:, -1]\n",
    "y_pred_gd = y_pred[:, -2]\n",
    "\n",
    "# Apply metrics\n",
    "\n",
    "accuracy_ds = accuracy_score(y_validation_ds, y_pred_ds)\n",
    "precision_ds = precision_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "recall_ds = recall_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "f1_ds = f1_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "\n",
    "accuracy_gd = accuracy_score(y_validation_gd, y_pred_gd)\n",
    "precision_gd= precision_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "recall_gd = recall_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "f1_gd = f1_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Metrics for the Generative Disorder:\")\n",
    "print(\"Accuracy:\", accuracy_gd)\n",
    "print(\"Precision:\", precision_gd)\n",
    "print(\"Recall:\", recall_gd)\n",
    "print(\"F1 Score:\", f1_gd)\n",
    "\n",
    "print(\"\\nMetrics for the Disorder Subclass:\")\n",
    "print(\"Accuracy:\", accuracy_ds)\n",
    "print(\"Precision:\", precision_ds)\n",
    "print(\"Recall:\", recall_ds)\n",
    "print(\"F1 Score:\", f1_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative Disorder\n",
    "\n",
    "\n",
    "class_labels_last_column = y.iloc[:, -2]\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts_gd = class_labels_last_column.value_counts()\n",
    "\n",
    "# Calculate the percentage of each class\n",
    "total_samples = len(class_labels_last_column)\n",
    "class_percentages = (class_counts_gd / total_samples) * 100\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_counts_gd.index, class_counts_gd, color='pink', alpha=0.7)\n",
    "\n",
    "# Adding percentage text on top of each bar\n",
    "for label, count, percentage in zip(class_counts_gd.index, class_counts_gd, class_percentages):\n",
    "    plt.text(label, count, f'{percentage:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Class Distribution - Generative Disorder')\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disorder Subclass\n",
    "\n",
    "# Assuming y is your original dataset\n",
    "class_labels_last_column = y.iloc[:, -1]\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts_ds = class_labels_last_column.value_counts()\n",
    "\n",
    "# Calculate the percentage of each class\n",
    "total_samples = len(class_labels_last_column)\n",
    "class_percentages = (class_counts_ds / total_samples) * 100\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_counts_ds.index, class_counts_ds, color='blue', alpha=0.7)\n",
    "\n",
    "# Adding percentage text on top of each bar\n",
    "for label, count, percentage in zip(class_counts_ds.index, class_counts_ds, class_percentages):\n",
    "    plt.text(label, count, f'{percentage:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Class Distribution - Disorder Subclass')\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the classes balanced by the classifier parameter (automatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation, validation and test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, train_size=0.5,  random_state=1) # training as 50%\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1) # test as 25% and validations as 25%\n",
    "\n",
    "# Select and train model of classifier\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', random_state=1, class_weight='balanced')\n",
    "\n",
    "clf = MultiOutputClassifier(svm_classifier)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_validation)\n",
    "\n",
    "y_validation_ds = y_validation.iloc[:, -1]\n",
    "y_validation_gd = y_validation.iloc[:, -2]\n",
    "\n",
    "y_pred_ds = y_pred[:, -1]\n",
    "y_pred_gd = y_pred[:, -2]\n",
    "\n",
    "# Apply metrics\n",
    "\n",
    "accuracy_ds = accuracy_score(y_validation_ds, y_pred_ds)\n",
    "precision_ds = precision_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "recall_ds = recall_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "f1_ds = f1_score(y_validation_ds, y_pred_ds, average='weighted')\n",
    "\n",
    "accuracy_gd = accuracy_score(y_validation_gd, y_pred_gd)\n",
    "precision_gd= precision_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "recall_gd = recall_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "f1_gd = f1_score(y_validation_gd, y_pred_gd, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Metrics for the Generative Disorder:\")\n",
    "print(\"Accuracy:\", accuracy_gd)\n",
    "print(\"Precision:\", precision_gd)\n",
    "print(\"Recall:\", recall_gd)\n",
    "print(\"F1 Score:\", f1_gd)\n",
    "\n",
    "print(\"\\nMetrics for the Disorder Subclass:\")\n",
    "print(\"Accuracy:\", accuracy_ds)\n",
    "print(\"Precision:\", precision_ds)\n",
    "print(\"Recall:\", recall_ds)\n",
    "print(\"F1 Score:\", f1_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the class weights manually calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class labels and their counts\n",
    "class_labels_gd = y.iloc[:, -2]\n",
    "class_counts_gd = class_labels_gd.value_counts()\n",
    "class_labels_ds = y.iloc[:, -1]\n",
    "class_counts_ds = class_labels_ds.value_counts()\n",
    "\n",
    "\n",
    "# Calculate class weights for Generative Disorder\n",
    "total_samples_gd = len(class_labels_gd)\n",
    "class_weights_gd = {label: 1 - (count / total_samples_gd) for label, count in class_counts_gd.items()}\n",
    "print(\"Class Weights Generative Disorder:\", class_weights_gd)\n",
    "\n",
    "# Calculate class weights for Disorder Subclass\n",
    "total_samples_ds = len(class_labels_ds)\n",
    "class_weights_ds = {label: 1 - (count / total_samples_ds) for label, count in class_counts_ds.items()}\n",
    "print(\"Class Weights Disorder Subclass:\", class_weights_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation, validation and test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, train_size=0.5,  random_state=1) # training as 50%\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1) # test as 25% and validations as 25%\n",
    "\n",
    "\n",
    "# Training Generative Disorder\n",
    "svm_classifier_gd = SVC(kernel='linear', random_state=1, class_weight=class_weights_gd)\n",
    "svm_classifier_gd.fit(X_train, y_train.iloc[:, -2])\n",
    "\n",
    "# Predictions for Generative Disorder\n",
    "y_pred_gd = svm_classifier_gd.predict(X_validation)\n",
    "\n",
    "# Metrics for Generative Disorder\n",
    "accuracy_gd = accuracy_score(y_validation.iloc[:, -2], y_pred_gd)\n",
    "precision_gd = precision_score(y_validation.iloc[:, -2], y_pred_gd, average='weighted')\n",
    "recall_gd = recall_score(y_validation.iloc[:, -2], y_pred_gd, average='weighted')\n",
    "f1_gd = f1_score(y_validation.iloc[:, -2], y_pred_gd, average='weighted')\n",
    "\n",
    "# Training Disorder Subclass\n",
    "svm_classifier_ds = SVC(kernel='linear', random_state=1, class_weight=class_weights_ds)\n",
    "svm_classifier_ds.fit(X_train, y_train.iloc[:, -1])\n",
    "\n",
    "# Predictions for Disorder Subclass\n",
    "y_pred_ds = svm_classifier_ds.predict(X_validation)\n",
    "\n",
    "# Metrics for Disorder Subclass\n",
    "accuracy_ds = accuracy_score(y_validation.iloc[:, -1], y_pred_ds)\n",
    "precision_ds = precision_score(y_validation.iloc[:, -1], y_pred_ds, average='weighted')\n",
    "recall_ds = recall_score(y_validation.iloc[:, -1], y_pred_ds, average='weighted')\n",
    "f1_ds = f1_score(y_validation.iloc[:, -1], y_pred_ds, average='weighted')\n",
    "\n",
    "# Print metrics for Generative Disorder\n",
    "print(\"Metrics for Generative Disorder:\")\n",
    "print(\"Accuracy:\", accuracy_gd)\n",
    "print(\"Precision:\", precision_gd)\n",
    "print(\"Recall:\", recall_gd)\n",
    "print(\"F1 Score:\", f1_gd)\n",
    "\n",
    "# Print metrics for Disorder Subclass\n",
    "print(\"\\nMetrics for Disorder Subclass:\")\n",
    "print(\"Accuracy:\", accuracy_ds)\n",
    "print(\"Precision:\", precision_ds)\n",
    "print(\"Recall:\", recall_ds)\n",
    "print(\"F1 Score:\", f1_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning: Randomized CV (failed bc too much time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "print(\"Dataset Size:\", dataset.shape)\n",
    "\n",
    "# Replace 'Unknown' with NaN in Target\n",
    "dataset['Genetic Disorder'].replace('Unknown', np.nan, inplace=True)\n",
    "dataset['Disorder Subclass'].replace('Unknown', np.nan, inplace=True)\n",
    "\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "# Allocate features and labels\n",
    "X = dataset.iloc[:, :-2]  # Features\n",
    "y = dataset.iloc[:, -2:]  # Labels (last two columns)\n",
    "\n",
    "# Perform one-hot encoding on the categorical features\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Check if the target variable has more than 2 classes\n",
    "if y.nunique().any() > 2:\n",
    "    y = pd.get_dummies(y, drop_first=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, train_size=0.5, random_state=1)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# Define the parameter grid for randomized search\n",
    "param_dist = {'C': [0.1, 1, 10],\n",
    "              'kernel': ['linear', 'rbf'],\n",
    "              'gamma': ['scale', 'auto', 0.1, 1, 10]}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(random_state=1, class_weight='balanced')\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(svm_classifier, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=1)\n",
    "\n",
    "# Perform Randomized Search for Generative Disorder\n",
    "random_search.fit(X_train, y_train.iloc[:, -2])\n",
    "\n",
    "# Get the best hyperparameters for Generative Disorder\n",
    "best_params_gd = random_search.best_params_\n",
    "\n",
    "# Print the best hyperparameters for Generative Disorder\n",
    "print(\"Best Hyperparameters for Generative Disorder:\", best_params_gd)\n",
    "\n",
    "# Train SVM with the best hyperparameters for Generative Disorder\n",
    "svm_classifier_gd = SVC(**best_params_gd, random_state=1)\n",
    "svm_classifier_gd.fit(X_train, y_train.iloc[:, -2])\n",
    "\n",
    "# Predictions for Generative Disorder\n",
    "y_pred_gd = svm_classifier_gd.predict(X_validation)\n",
    "\n",
    "# Metrics for Generative Disorder\n",
    "classification_rep_gd = classification_report(y_validation.iloc[:, -2], y_pred_gd, target_names=y.iloc[:, -2].columns)\n",
    "print(\"Metrics for Generative Disorder:\")\n",
    "print(classification_rep_gd)\n",
    "\n",
    "# Perform Randomized Search for Disorder Subclass\n",
    "random_search.fit(X_train, y_train.iloc[:, -1])\n",
    "\n",
    "# Get the best hyperparameters for Disorder Subclass\n",
    "best_params_ds = random_search.best_params_\n",
    "\n",
    "# Print the best hyperparameters for Disorder Subclass\n",
    "print(\"\\nBest Hyperparameters for Disorder Subclass:\", best_params_ds)\n",
    "\n",
    "# Train SVM with the best hyperparameters for Disorder Subclass\n",
    "svm_classifier_ds = SVC(**best_params_ds, random_state=1)\n",
    "svm_classifier_ds.fit(X_train, y_train.iloc[:, -1])\n",
    "\n",
    "# Predictions for Disorder Subclass\n",
    "y_pred_ds = svm_classifier_ds.predict(X_validation)\n",
    "\n",
    "# Metrics for Disorder Subclass\n",
    "classification_rep_ds = classification_report(y_validation.iloc[:, -1], y_pred_ds, target_names=y.iloc[:, -1].columns)\n",
    "print(\"\\nMetrics for Disorder Subclass:\")\n",
    "print(classification_rep_ds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
