{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "dataset= pd.read_csv('dataset.csv')\n",
    "\n",
    "# Alocate features and labels\n",
    "\n",
    "X = dataset.iloc[:, :-2]  # Features\n",
    "y = dataset.iloc[:, -2:]  # Labels (last two columns)\n",
    "\n",
    "# Perform one-hot encoding on the categorical features\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "# drop_first is used to drop one of the columns for each categorical feature to avoid multicollinearity.\n",
    "\n",
    "# Check if the target variable has more than 2 classes\n",
    "if y.nunique().any() > 2:\n",
    "    y = pd.get_dummies(y, drop_first=True)\n",
    "\n",
    "#label_encoder = LabelEncoder()\n",
    "#y = y.apply(lambda col: label_encoder.fit_transform(col)) # deal with multiclass and multioutput data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation, validation and test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.5,  random_state=1) # training as 50% \n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1) # test as 25% and validations as 25%\n",
    "\n",
    "# Select and train model of classifier\n",
    "\n",
    "clf = MultiOutputClassifier(tree.DecisionTreeClassifier(splitter = 'random', random_state = 1))\n",
    "# evaluate the change of the criterion from gini to entropy?\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_validation) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "# Separate the multi output targets\n",
    "y_validation_last1 = y_validation.iloc[:, -1]\n",
    "y_validation_last2 = y_validation.iloc[:, -2]\n",
    "\n",
    "y_pred_last1 = y_pred[:, -1]\n",
    "y_pred_last2 = y_pred[:, -2]\n",
    "\n",
    "\n",
    "# Apply metrics\n",
    "\n",
    "accuracy_last1 = accuracy_score(y_validation_last1, y_pred_last1)\n",
    "precision_last1 = precision_score(y_validation_last1, y_pred_last1, average='weighted')\n",
    "recall_last1 = recall_score(y_validation_last1, y_pred_last1, average='weighted')\n",
    "f1_last1 = f1_score(y_validation_last1, y_pred_last1, average='weighted')\n",
    "balanced_acc_last1 = balanced_accuracy_score(y_validation_last1, y_pred_last1)\n",
    "\n",
    "\n",
    "accuracy_last2 = accuracy_score(y_validation_last2, y_pred_last2)\n",
    "precision_last2 = precision_score(y_validation_last2, y_pred_last2, average='weighted')\n",
    "recall_last2 = recall_score(y_validation_last2, y_pred_last2, average='weighted')\n",
    "f1_last2 = f1_score(y_validation_last2, y_pred_last2, average='weighted')\n",
    "balanced_acc_last2 = balanced_accuracy_score(y_validation_last2, y_pred_last2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the last column:\n",
      "Accuracy: 0.2724144176779569\n",
      "Precision: 0.26906666136770363\n",
      "Recall: 0.2724144176779569\n",
      "F1 Score: 0.2702617678409767\n",
      "balanced accuracy: 0.21177961361331468\n",
      "\n",
      "Metrics for the second-to-last column:\n",
      "Accuracy: 0.44883173338163374\n",
      "Precision: 0.4410519740955179\n",
      "Recall: 0.44883173338163374\n",
      "F1 Score: 0.4442669535717083\n",
      "balanced accuracy: 0.3388344059462966\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for the last column:\")\n",
    "print(\"Accuracy:\", accuracy_last1)\n",
    "print(\"Precision:\", precision_last1)\n",
    "print(\"Recall:\", recall_last1)\n",
    "print(\"F1 Score:\", f1_last1)\n",
    "print(\"balanced accuracy:\", balanced_acc_last1)\n",
    "\n",
    "print(\"\\nMetrics for the second-to-last column:\")\n",
    "print(\"Accuracy:\", accuracy_last2)\n",
    "print(\"Precision:\", precision_last2)\n",
    "print(\"Recall:\", recall_last2)\n",
    "print(\"F1 Score:\", f1_last2)\n",
    "print(\"balanced accuracy:\", balanced_acc_last2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
