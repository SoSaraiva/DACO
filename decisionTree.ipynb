{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22083, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "dataset= pd.read_csv('dataset.csv')\n",
    "#print(dataset.head()) # to see first lines of dataset\n",
    "\n",
    "\n",
    "# Alocate features and labels\n",
    "\n",
    "X = dataset.iloc[:, :-2]  # Features\n",
    "y = dataset.iloc[:, -2:]  # Labels (last two columns)\n",
    "print (X.shape)\n",
    "\n",
    "# Perform one-hot encoding on the categorical features\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "# drop_first argument is used to drop one of the columns for each categorical feature to avoid multicollinearity.\n",
    "\n",
    "# Check if the target variable has more than 2 classes\n",
    "if y.nunique().any() > 2:\n",
    "    y = pd.get_dummies(y, drop_first=True)\n",
    "    # Apply one-hot encoding to y to represent each class as a separate binary column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12421, 17429) (4141, 17429) (5521, 17429)\n",
      "(12421, 2) (4141, 2) (5521, 2)\n"
     ]
    }
   ],
   "source": [
    "# split the data into validation, validation and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1) # train and validation as 75% and test as 25%\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # train as 75% and validation as 25%\n",
    "\n",
    "print(X_train.shape, X_validation.shape, X_test.shape)\n",
    "print(y_train.shape, y_validation.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and train model of classifier\n",
    "\n",
    "clf = MultiOutputClassifier(tree.DecisionTreeClassifier(splitter='random', random_state=1))\n",
    "# evaluate the change of the classifier from gini to entropy?\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_validation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set shape: (4141,)\n",
      "Predictions shape: (4141,)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "# Separate the multi output targets\n",
    "y_validation_last1 = y_validation.iloc[:, -1]\n",
    "y_validation_last2 = y_validation.iloc[:, -2]\n",
    "\n",
    "y_pred_last1 = y_pred[:, -1]\n",
    "y_pred_last2 = y_pred[:, -2]\n",
    "\n",
    "\n",
    "print(\"Validation set shape:\", y_validation_last2.shape)\n",
    "print(\"Predictions shape:\", y_pred_last2.shape)\n",
    "\n",
    "# Apply  metrics\n",
    "accuracy_last1 = accuracy_score(y_validation_last1, y_pred_last1)\n",
    "precision_last1 = precision_score(y_validation_last1, y_pred_last1, average='weighted')\n",
    "recall_last1 = recall_score(y_validation_last1, y_pred_last1, average='weighted')\n",
    "f1_last1 = f1_score(y_validation_last1, y_pred_last1, average='weighted')\n",
    "\n",
    "accuracy_last2 = accuracy_score(y_validation_last2, y_pred_last2)\n",
    "precision_last2 = precision_score(y_validation_last2, y_pred_last2, average='weighted')\n",
    "recall_last2 = recall_score(y_validation_last2, y_pred_last2, average='weighted')\n",
    "f1_last2 = f1_score(y_validation_last2, y_pred_last2, average='weighted')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the last column:\n",
      "Accuracy: 0.2750543347017629\n",
      "Precision: 0.2732284103025439\n",
      "Recall: 0.2750543347017629\n",
      "F1 Score: 0.27392248851277445\n",
      "\n",
      "Metrics for the second-to-last column:\n",
      "Accuracy: 0.4296063752716735\n",
      "Precision: 0.4300198556219927\n",
      "Recall: 0.4296063752716735\n",
      "F1 Score: 0.42973923300440164\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for the last column:\")\n",
    "print(\"Accuracy:\", accuracy_last1)\n",
    "print(\"Precision:\", precision_last1)\n",
    "print(\"Recall:\", recall_last1)\n",
    "print(\"F1 Score:\", f1_last1)\n",
    "\n",
    "print(\"\\nMetrics for the second-to-last column:\")\n",
    "print(\"Accuracy:\", accuracy_last2)\n",
    "print(\"Precision:\", precision_last2)\n",
    "print(\"Recall:\", recall_last2)\n",
    "print(\"F1 Score:\", f1_last2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
