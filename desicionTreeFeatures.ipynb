{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, hamming_loss, f1_score, recall_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "provided_weights_genetic_disorder = {\n",
    "    'Mitochondrial genetic inheritance disorders': 0.48794813542417026,\n",
    "    'Single-gene inheritance diseases': 0.6160580705934504,\n",
    "    'Multifactorial genetic inheritance disorders': 0.8959937939823793\n",
    "}\n",
    "\n",
    "provided_weights_subclass_disorder = {\n",
    "    'Leigh syndrome': 0.740510888236272,\n",
    "    'Mitochondrial myopathy': 0.7799634288247355,\n",
    "    'Cystic fibrosis': 0.8257328087770821,\n",
    "    'Tay-Sachs': 0.8583698121571453,\n",
    "    'Diabetes': 0.9084058292236937,\n",
    "    'Hemochromatosis': 0.9319554496592232,\n",
    "    \"Leber's hereditary optic neuropathy\": 0.9674738183631628,\n",
    "    \"Alzheimer's\": 0.9926303540754696,\n",
    "    'Cancer': 0.9949576106832161\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset= pd.read_csv('dataset.csv')\n",
    "#print(dataset.columns)\n",
    "\n",
    "# Replace 'Unknown' with NaN\n",
    "dataset.replace('Unknown', np.nan, inplace=True)\n",
    "\n",
    "# Eliminate samples with\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Features to use\n",
    "features = ['Genes in mother\\'s side', 'Inherited from father', 'Symptom 2', 'Symptom 3', 'Symptom 4', 'Symptom 5']\n",
    "targets = ['Genetic Disorder', 'Disorder Subclass']\n",
    "\n",
    "# Select only the desired columns\n",
    "selected_columns = features + targets\n",
    "dataset = dataset[selected_columns]\n",
    "\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create a copy for encoding\n",
    "dataset_encoded = dataset.copy()\n",
    "\n",
    "quantitative_with_unknowns_or_ordered_columns = [\n",
    "    'Patient Age', \"Mother's age\", \"Father's age\", 'No. of previous abortion',\n",
    "    'White Blood cell count (thousand per microliter)']\n",
    "\n",
    "\n",
    "\n",
    "# Encode target variables 'Genetic Disorder' and 'Disorder Subclass'\n",
    "# Create mapping\n",
    "genetic_disorder_mapping = {label: i for i, label in enumerate(dataset_encoded['Genetic Disorder'].unique()) if pd.notna(label)}\n",
    "disorder_subclass_mapping = {label: i for i, label in enumerate(dataset_encoded['Disorder Subclass'].unique())}\n",
    "\n",
    "# Replace each original value with its corresponding encoded value as per the mapping\n",
    "dataset_encoded['Genetic Disorder'] = dataset_encoded['Genetic Disorder'].map(genetic_disorder_mapping)\n",
    "dataset_encoded['Disorder Subclass'] = dataset_encoded['Disorder Subclass'].map(disorder_subclass_mapping)\n",
    "\n",
    "\n",
    "# Correspond weights to classes\n",
    "# Get values mapped\n",
    "encoded_values_genetic_disorder = dataset_encoded['Genetic Disorder'].unique()\n",
    "encoded_values_disorder_subclass = dataset_encoded['Disorder Subclass'].unique()\n",
    "\n",
    "# Inverse mappings to get back the original names\n",
    "inverse_genetic_disorder_mapping = {i: label for label, i in genetic_disorder_mapping.items()}\n",
    "inverse_disorder_subclass_mapping = {i: label for label, i in disorder_subclass_mapping.items()}\n",
    "\n",
    "# Map encoded values back to original names\n",
    "names_genetic_disorder = [inverse_genetic_disorder_mapping[i] for i in encoded_values_genetic_disorder]\n",
    "names_disorder_subclass = [inverse_disorder_subclass_mapping[i] for i in encoded_values_disorder_subclass]\n",
    "\n",
    "# Associate weights with encoded values\n",
    "weights_genetic_disorder = {encoded_value: provided_weights_genetic_disorder[name] for encoded_value, name in zip(encoded_values_genetic_disorder, names_genetic_disorder)}\n",
    "weights_disorder_subclass = {encoded_value: provided_weights_subclass_disorder[name] for encoded_value, name in zip(encoded_values_disorder_subclass, names_disorder_subclass)}\n",
    "\n",
    "# Combine both class weights into a dictionary\n",
    "class_weights = {'Genetic Disorder': weights_genetic_disorder, 'Disorder Subclass': weights_disorder_subclass}\n",
    "\n",
    "\n",
    "class_weights_genetic_disorder = {0: 0.48794813542417026, 1: 0.8959937939823793, 2: 0.6160580705934504}\n",
    "\n",
    "class_weights_disorder_subclass = {0: 0.740510888236272, 1: 0.9084058292236937, 2: 0.7799634288247355, \n",
    "                                   3: 0.8257328087770821, 4: 0.8583698121571453, 5: 0.9674738183631628, \n",
    "                                   6: 0.9319554496592232, 7: 0.9926303540754696, 8: 0.9949576106832161}\n",
    "\n",
    "# Allocate features and labels\n",
    "X = dataset_encoded.drop(columns=['Genetic Disorder', 'Disorder Subclass'])\n",
    "y = dataset_encoded[['Genetic Disorder', 'Disorder Subclass']]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8048\\446752395.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights_disorder_subclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Fit the models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdt_genetic_disorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Genetic Disorder'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Assuming genetic disorder labels are in the first column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdt_disorder_subclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Disorder Subclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Assuming disorder subclass labels start from the second column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Predict using the trained models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Sofia\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1149\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Sofia\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \"\"\"\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         super()._fit(\n\u001b[0m\u001b[0;32m    960\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Sofia\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    238\u001b[0m             check_X_params = dict(\n\u001b[0;32m    239\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             )\n\u001b[0;32m    241\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    243\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             )\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Sofia\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    613\u001b[0m                 \u001b[1;31m# :(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Sofia\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    912\u001b[0m                         )\n\u001b[0;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m                 raise ValueError(\n\u001b[0;32m    918\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32mc:\\Users\\Sofia\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Sofia\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         if (\n\u001b[0;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Yes'"
     ]
    }
   ],
   "source": [
    "\n",
    "# DecisionTreeClassifier for genetic disorder\n",
    "dt_genetic_disorder = DecisionTreeClassifier(\n",
    "    criterion='gini', max_depth=10, max_features='log2', min_samples_leaf=1, min_samples_split=10, splitter='random',\n",
    "    class_weight=class_weights_genetic_disorder\n",
    ")\n",
    "\n",
    "# DecisionTreeClassifier for disorder subclass\n",
    "dt_disorder_subclass = DecisionTreeClassifier(\n",
    "    criterion='entropy', max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter='random',\n",
    "    class_weight=class_weights_disorder_subclass\n",
    ")\n",
    "\n",
    "# Fit the models\n",
    "dt_genetic_disorder.fit(X_train, y_train['Genetic Disorder'])  # Assuming genetic disorder labels are in the first column\n",
    "dt_disorder_subclass.fit(X_train, y_train['Disorder Subclass'])  # Assuming disorder subclass labels start from the second column\n",
    "\n",
    "# Predict using the trained models\n",
    "y_pred_genetic_disorder = dt_genetic_disorder.predict(X_test)\n",
    "y_pred_disorder_subclass = dt_disorder_subclass.predict(X_test)\n",
    "\n",
    "# Combine the predictions into a single array if needed\n",
    "y_pred = np.column_stack((y_pred_genetic_disorder, y_pred_disorder_subclass))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_new is DataFrames\n",
    "y_test_columns = y_test.columns[:]\n",
    "# Convert y_pred_new to a DataFrame\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=y_test_columns)\n",
    "\n",
    "balanced_acc_scores = {}\n",
    "\n",
    "for column in y_test_columns:\n",
    "    y_test_column = y_test[column]\n",
    "    y_pred_column = y_pred_df[column]\n",
    "    \n",
    "    balanced_acc_scores[column] = balanced_accuracy_score(y_test_column, y_pred_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report for each output separately\n",
    "\n",
    "y_test_array = y_test.to_numpy()\n",
    "\n",
    "hamming_loss_genetic_disorder = hamming_loss(y_test_array[:, 0], y_pred[:, 0])\n",
    "hamming_loss_disorder_subclass = hamming_loss(y_test_array[:, 1], y_pred[:, 1])\n",
    "\n",
    "f1_score_genetic_disorder = f1_score(y_test_array[:, 0], y_pred[:, 0], average='weighted')\n",
    "f1_score_disorder_subclass = f1_score(y_test_array[:, 1], y_pred[:, 1], average='weighted')\n",
    "\n",
    "recall_genetic_disorder = recall_score(y_test_array[:, 0], y_pred[:, 0], average='weighted')\n",
    "recall_disorder_subclass = recall_score(y_test_array[:, 1], y_pred[:, 1], average='weighted')\n",
    "\n",
    "accuracy_genetic_disorder = accuracy_score(y_test_array[:, 0], y_pred[:, 0])\n",
    "accuracy_disorder_subclass = accuracy_score(y_test_array[:, 1], y_pred[:, 1])\n",
    "\n",
    "balanced_accuracy_genetic_disorder = balanced_accuracy_score(y_test_array[:, 0], y_pred[:, 0])\n",
    "balanced_accuracy_disorder_subclass = balanced_accuracy_score(y_test_array[:, 1], y_pred[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use dataset without Cancer and Alzeimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named dataset\n",
    "filtered_dataset = dataset_encoded[(dataset['Disorder Subclass'] != 7) & (dataset['Disorder Subclass'] != 8)]\n",
    "\n",
    "# Update your X and y with the filtered dataset\n",
    "X_filtered = filtered_dataset.drop(columns=['Genetic Disorder', 'Disorder Subclass'])\n",
    "y_filtered = filtered_dataset[['Genetic Disorder', 'Disorder Subclass']]\n",
    "\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_filtered, y_filtered, train_size=0.75,  random_state=1) # training as 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier for genetic disorder\n",
    "dt_genetic_disorder_new = DecisionTreeClassifier(\n",
    "    criterion='gini', max_depth=10, max_features='log2', min_samples_leaf=1, min_samples_split=10, splitter='random',\n",
    "    class_weight=class_weights_genetic_disorder\n",
    ")\n",
    "\n",
    "# DecisionTreeClassifier for disorder subclass\n",
    "dt_disorder_subclass_new = DecisionTreeClassifier(\n",
    "    criterion='entropy', max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter='random',\n",
    "    class_weight=class_weights_disorder_subclass\n",
    ")\n",
    "\n",
    "# Fit the models\n",
    "dt_genetic_disorder.fit(X_train, y_train['Genetic Disorder'])  # Assuming genetic disorder labels are in the first column\n",
    "dt_disorder_subclass.fit(X_train, y_train['Disorder Subclass'])  # Assuming disorder subclass labels start from the second column\n",
    "\n",
    "# Predict using the trained models\n",
    "y_pred_genetic_disorder_new = dt_genetic_disorder.predict(X_test)\n",
    "y_pred_disorder_subclass_new = dt_disorder_subclass.predict(X_test)\n",
    "\n",
    "# Combine the predictions into a single array if needed\n",
    "y_pred_new = np.column_stack((y_pred_genetic_disorder_new, y_pred_disorder_subclass_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_new is DataFrames\n",
    "y_test_columns_new = y_test_new.columns[:]\n",
    "# Convert y_pred_new to a DataFrame\n",
    "y_pred_df_new = pd.DataFrame(y_pred_new, columns=y_test_columns_new)\n",
    "\n",
    "balanced_acc_scores_new = {}\n",
    "\n",
    "for column in y_test_columns:\n",
    "    y_test_column_new = y_test_new[column]\n",
    "    y_pred_column_new = y_pred_df_new[column]\n",
    "    \n",
    "    balanced_acc_scores_new[column] = balanced_accuracy_score(y_test_column_new, y_pred_column_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report for each output separately\n",
    "y_test_array_new = y_test_new.to_numpy()\n",
    "\n",
    "hamming_loss_genetic_disorder_new = hamming_loss(y_test_array_new[:, 0], y_pred_new[:, 0])\n",
    "hamming_loss_disorder_subclass_new = hamming_loss(y_test_array_new[:, 1], y_pred_new[:, 1])\n",
    "\n",
    "f1_score_genetic_disorder_new = f1_score(y_test_array_new[:, 0], y_pred_new[:, 0], average='weighted')\n",
    "f1_score_disorder_subclass_new = f1_score(y_test_array_new[:, 1], y_pred_new[:, 1], average='weighted')\n",
    "\n",
    "recall_genetic_disorder_new = recall_score(y_test_array_new[:, 0], y_pred_new[:, 0], average='weighted')\n",
    "recall_disorder_subclass_new = recall_score(y_test_array_new[:, 1], y_pred_new[:, 1], average='weighted')\n",
    "\n",
    "balanced_accuracy_genetic_disorder_new = balanced_accuracy_score(y_test_array_new[:, 0], y_pred_new[:, 0])\n",
    "balanced_accuracy_disorder_subclass_new = balanced_accuracy_score(y_test_array_new[:, 1], y_pred_new[:, 1])\n",
    "\n",
    "accuracy_genetic_disorder_new = accuracy_score(y_test_array_new[:, 0], y_pred_new[:, 0])\n",
    "accuracy_disorder_subclass_new = accuracy_score(y_test_array_new[:, 1], y_pred_new[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for Genetic Disorder:\n",
      "Hamming Loss for Genetic Disorder: 0.5418326693227091\n",
      "F1 Score for Genetic Disorder: 0.4632332113552061\n",
      "Recall for Genetic Disorder: 0.4581673306772908\n",
      "Accuracy for Genetic Disorder: 0.4581673306772908\n",
      "Balanced Accuracy for Genetic Disorder: 0.3891343467675498\n",
      "\n",
      "Classification for Disorder Subclass:\n",
      "Hamming Loss for Disorder Subclass: 0.8406374501992032\n",
      "F1 Score for Disorder Subclass: 0.16130291452767645\n",
      "Recall for Disorder Subclass: 0.1593625498007968\n",
      "Balanced Accuracy for Disorder Subclass: 0.08856456724103784\n",
      "Accuracy for Disorder Subclass: 0.1593625498007968\n",
      "\n",
      " ------------ Without Cancer and Alzeimer samples --------------\n",
      "Classification for Genetic Disorder:\n",
      "\n",
      "Hamming Loss for Genetic Disorder: 0.5776892430278885\n",
      "F1 Score for Genetic Disorder: 0.4155330557469371\n",
      "Recall for Genetic Disorder: 0.42231075697211157\n",
      "Balanced Accuracy for Genetic Disorder: 0.3028474648036414\n",
      "Accuracy for Genetic Disorder: 0.42231075697211157\n",
      "\n",
      "Classification for Disorder Subclass:\n",
      "Hamming Loss for Disorder Subclass: 0.8127490039840638\n",
      "F1 Score for Disorder Subclass: 0.18828355667400215\n",
      "Recall for Disorder Subclass: 0.18725099601593626\n",
      "Balanced Accuracy for Disorder Subclass: 0.11712715389185978\n",
      "Accuracy for Disorder Subclass: 0.18725099601593626\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification for Genetic Disorder:\")\n",
    "\n",
    "print(\"Hamming Loss for Genetic Disorder:\", hamming_loss_genetic_disorder)\n",
    "print(\"F1 Score for Genetic Disorder:\", f1_score_genetic_disorder)\n",
    "print(\"Recall for Genetic Disorder:\", recall_genetic_disorder)\n",
    "print(\"Accuracy for Genetic Disorder:\", accuracy_genetic_disorder)\n",
    "print(\"Balanced Accuracy for Genetic Disorder:\", balanced_accuracy_genetic_disorder)\n",
    "\n",
    "print(\"\\nClassification for Disorder Subclass:\")\n",
    "\n",
    "print(\"Hamming Loss for Disorder Subclass:\", hamming_loss_disorder_subclass)\n",
    "print(\"F1 Score for Disorder Subclass:\", f1_score_disorder_subclass)\n",
    "print(\"Recall for Disorder Subclass:\", recall_disorder_subclass)\n",
    "print(\"Balanced Accuracy for Disorder Subclass:\", balanced_accuracy_disorder_subclass)\n",
    "print(\"Accuracy for Disorder Subclass:\", accuracy_disorder_subclass)\n",
    "\n",
    "\n",
    "print(\"\\n ------------ Without Cancer and Alzeimer samples --------------\")\n",
    "\n",
    "print(\"Classification for Genetic Disorder:\")\n",
    "\n",
    "print(\"\\nHamming Loss for Genetic Disorder:\", hamming_loss_genetic_disorder_new)\n",
    "print(\"F1 Score for Genetic Disorder:\", f1_score_genetic_disorder_new)\n",
    "print(\"Recall for Genetic Disorder:\", recall_genetic_disorder_new)\n",
    "print(\"Balanced Accuracy for Genetic Disorder:\", balanced_accuracy_genetic_disorder_new)\n",
    "print(\"Accuracy for Genetic Disorder:\", accuracy_genetic_disorder_new)\n",
    "\n",
    "print(\"\\nClassification for Disorder Subclass:\")\n",
    "\n",
    "print(\"Hamming Loss for Disorder Subclass:\", hamming_loss_disorder_subclass_new)\n",
    "print(\"F1 Score for Disorder Subclass:\", f1_score_disorder_subclass_new)\n",
    "print(\"Recall for Disorder Subclass:\", recall_disorder_subclass_new)\n",
    "print(\"Balanced Accuracy for Disorder Subclass:\", balanced_accuracy_disorder_subclass_new)\n",
    "print(\"Accuracy for Disorder Subclass:\", accuracy_disorder_subclass_new)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
